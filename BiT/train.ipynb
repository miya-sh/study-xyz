{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigTransfer (BiT) Fine-Tuning\n",
    "\n",
    "- 参考資料  \n",
    "  https://blog.tensorflow.org/2020/05/bigtransfer-bit-state-of-art-transfer-learning-computer-vision.html  \n",
    "  https://github.com/google-research/big_transfer/tree/master/colabs\n",
    "\n",
    "- BiTモデルについてる **S, M, L** の意味  \n",
    "  学習させたデータセットの違い。**L** は非公開。\n",
    "\n",
    "|  モデル名  |  データセット                 |\n",
    "|  :--:     |  :---:                      |\n",
    "|  BiT-S    |  ILSVRC-2012 (1.3M images)  |\n",
    "|  BiT-M    |  ImageNet-21k (14M images)  |\n",
    "|  BiT-L    |  JFT (300M images)          |\n",
    "\n",
    "- BiTモデルについてる **R-??x?** の意味  \n",
    "  BiTモデルはResNetを利用しているので、そこの情報。R50x3 → 50層のResNetで、各層の幅が通常の3倍。\n",
    "\n",
    "|  ResNet  |  パラメータ数（概数）  |\n",
    "|  :----:  |  :----:  |\n",
    "|  R50x1   |   23M    |\n",
    "|  R101x1  |   42M    |\n",
    "|  R50x3   |  211M    |\n",
    "|  R101x3  |  381M    |\n",
    "|  R152x4  |  928M    |\n",
    "\n",
    "パラメータ数確認コード。\n",
    "\n",
    "```python\n",
    "model = tfhub.KerasLayer('https://tfhub.dev/google/bit/s-r50x1/1')\n",
    "print(sum(tf.math.reduce_prod(w.shape).numpy() for w in model.weights))\n",
    "```\n",
    "\n",
    "## BiT-HyperRule\n",
    "\n",
    "ファインチューニングのためのヒューリスティックな方法\n",
    "\n",
    "### データ拡張・調整\n",
    "\n",
    "![BigTransfer (BiT): State-of-the-art transfer learning for computer vision; Table1](https://4.bp.blogspot.com/-54vXxLE1bqU/XsMCth3HvzI/AAAAAAAADEs/UVrCWT0o6wYPtCpat81ApNGPus16-CHzgCLcBGAsYHQ/s1600/table1.jpg)\n",
    "![BigTransfer (BiT): State-of-the-art transfer learning for computer vision; Table2](https://3.bp.blogspot.com/-2JVDJV2A5Uo/XsMT-JfSJtI/AAAAAAAADFQ/UqcoPn11wFAudJJxkdzYxb3tAxBpgoGMQCLcBGAsYHQ/s1600/table%2B2.jpg)\n",
    "\n",
    "併せて、ランダムに左右反転も入れる。バリデーション用データにはリサイズだけ行えば良い。\n",
    "\n",
    "- 正解ラベルと乖離が出るので、タスクによっては行わないデータ拡張。\n",
    "  - 物体の数え上げ ⇒ ランダムクロップはNG\n",
    "  - 物体の位置特定 ⇒ ランダムフリップはNG\n",
    "\n",
    "\n",
    "#### MixUp\n",
    "\n",
    "参考: https://github.com/google-research/big_transfer/blob/master/input_pipeline_tf2_or_jax.py#L118\n",
    "\n",
    "- データセットに適応するタイミングは **ミニバッチ化`batch()`の後**。\n",
    "- MixUpが絡むので、ラベルはOne-Hotベクトルにする。\n",
    "- mixup.ipynbで結果参照。\n",
    "\n",
    "### バッチサイズ = 512\n",
    "\n",
    "搭載メモリに合わせて調整する。\n",
    "\n",
    "### 最適化アルゴリズム = SGD\n",
    "\n",
    "- Learning rate: 0.003\n",
    "- Momentum: 0.9\n",
    "\n",
    "学習率は初期値。学習中の学習率の変更を、以下のスケジューリングを行う。\n",
    "\n",
    "#### 学習率のスケジューリング\n",
    "\n",
    "学習の進捗が、全体の30%, 60%, 90%になるタイミングで、学習率を\n",
    "$ \\frac{1}{10} $\n",
    "ずつ減衰させる。\n",
    "\n",
    "公式サンプルコードでは、厳密に30%, 60%, 90%で区切っていない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataclasses\n",
    "import logging\n",
    "import pathlib\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "class WrappedBiT(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, classes=2, bit_type='m-r50x1', version='1'):\n",
    "        super().__init__()\n",
    "        self._head = tf.keras.layers.Dense(classes, kernel_initializer='zeros')\n",
    "        self._bit = tfhub.KerasLayer(f'https://tfhub.dev/google/bit/{bit_type}/{version}')\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        features = self._bit(inputs)\n",
    "        return self._head(features)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class HyperRule:\n",
    "    schedule_len: int\n",
    "    resize_edge: int\n",
    "    crop_size: int\n",
    "    optimizer: tf.keras.optimizers.Optimizer\n",
    "\n",
    "    def __init__(self, image_edge: int, dataset_size: int, batch_size=512):\n",
    "        assert 512 % batch_size == 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if image_edge < 96:\n",
    "            self.resize_edge, self.crop_size = 160, 128\n",
    "        else:\n",
    "            self.resize_edge, self.crop_size = 512, 480\n",
    "\n",
    "        if dataset_size < 20 * 10 ** 3:\n",
    "            schedule_len, boundaries = 500, [200, 300, 400]\n",
    "            self.mixup = lambda image, label: (image, label)  # dummy\n",
    "        elif 20 * 10 ** 3 <= dataset_size < 500 * 10 ** 3:\n",
    "            schedule_len, boundaries = 10000, [3000, 6000, 9000]\n",
    "        else:\n",
    "            schedule_len, boundaries = 20000, [6000, 12000, 18000]\n",
    "        self.schedule_len = schedule_len * 512 // batch_size\n",
    "\n",
    "        lr = 0.003 * batch_size / 512\n",
    "        lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            boundaries=boundaries, values=[lr, lr * 1e-1, lr * 1e-2, lr * 1e-3])\n",
    "        self.optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=lr_schedule, momentum=0.9)\n",
    "\n",
    "    def mixup(self, image, label):\n",
    "        beta_dist = tfp.distributions.Beta(0.1, 0.1)  # alpha = 0.1\n",
    "        beta = tf.cast(beta_dist.sample([]), tf.float32)\n",
    "        image = (beta * image + (1 - beta) * tf.reverse(image, axis=[0]))\n",
    "        label = (beta * label + (1 - beta) * tf.reverse(label, axis=[0]))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットに設定を盛り込む\n",
    "\n",
    "`setup_dataset_and_hyperrule`\n",
    "\n",
    "- キャッシュ、シャッフル などHyperRule以外\n",
    "- HyperRule\n",
    "  - リサイズ\n",
    "  - （学習用データのみ）クロップ、左右反転、MixUp\n",
    "\n",
    "MixUpはバッチ後。挙動などは、mixup.ipynb確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataset_and_hyperrule(ds_factory, cache_dir, buffer_size=None, batch_size=512):\n",
    "    def resize_normalize(image, label):\n",
    "        image = tf.image.resize(image, [rule.resize_edge, rule.resize_edge],\n",
    "                                method=tf.image.ResizeMethod.BILINEAR)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        label = tf.one_hot(label, len(label_names))\n",
    "        return image, label\n",
    "\n",
    "    def random_sampling(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_crop(image, [rule.crop_size, rule.crop_size, 3])\n",
    "        return image, label\n",
    "\n",
    "    (ds_train, ds_train_size), (ds_test, _), label_names, image_edge = ds_factory()\n",
    "\n",
    "    rule = HyperRule(image_edge=image_edge, dataset_size=ds_train_size, batch_size=batch_size)\n",
    "    ds_train = (ds_train\n",
    "                .map(resize_normalize, tf.data.experimental.AUTOTUNE)\n",
    "                .cache(str(cache_dir / 'train'))\n",
    "                .shuffle(buffer_size or ds_train_size)\n",
    "                .repeat()\n",
    "                .map(random_sampling, tf.data.experimental.AUTOTUNE)\n",
    "                .batch(rule.batch_size)\n",
    "                .map(rule.mixup, tf.data.experimental.AUTOTUNE)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "    ds_test = (ds_test\n",
    "               .map(resize_normalize, tf.data.experimental.AUTOTUNE)\n",
    "               .cache(str(cache_dir / 'test'))\n",
    "               .batch(rule.batch_size)\n",
    "               .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    return rule, ds_train, ds_test, label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset_cats_vs_dogs`\n",
    "\n",
    "カタログ（ https://www.tensorflow.org/datasets/catalog/overview ）から、犬猫を選択。\n",
    "\n",
    "一辺96px以下になるような画像はフィルター（除外）している。\n",
    "残った全体の90%を学習、10%をバリデーションに使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_cats_vs_dogs():\n",
    "    def filter_small(image, _):\n",
    "        return tf.reduce_all(tf.shape(image)[:2] > tf.constant(96))\n",
    "\n",
    "    ds_org: tf.data.Dataset\n",
    "    (ds_org, ), info = tfds.load(name='cats_vs_dogs', with_info=True, as_supervised=True, split=['train'])\n",
    "    ds_filtered = ds_org.filter(filter_small)\n",
    "\n",
    "    # filter smaller than 96x96\n",
    "    num_samples = ds_filtered.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
    "    num_samples_train = int(num_samples * 0.9)\n",
    "    ds_train = ds_filtered.take(num_samples_train)\n",
    "    ds_test = ds_filtered.skip(num_samples_train)\n",
    "\n",
    "    label_names = info.features['label'].names\n",
    "    return (ds_train, num_samples_train), (ds_test, num_samples - num_samples_train), label_names, 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset_mydataset`\n",
    "\n",
    "自分でデータ持ってる用。フィルターなどやっていることは一緒。\n",
    "\n",
    "学習／バリデーションに分けるのは、シャッフルした後。  \n",
    "パス情報なら、メモリへの負担は比較的マシやろと乱暴に全体シャッフルしてる。あんまよくないと思う。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_mydataset():\n",
    "    def filter_small(image, _):\n",
    "        return tf.reduce_all(tf.shape(image)[:2] > tf.constant(96))\n",
    "\n",
    "    def generator():\n",
    "        path_iter = itertools.chain(pathlib.Path('train/cat').iterdir(), pathlib.Path('train/dog').iterdir())\n",
    "        path_list = list(path_iter)\n",
    "        for path in filter(lambda p: p.suffix in {'.png', '.jpg'}, random.sample(path_list, len(path_list))):\n",
    "            try:\n",
    "                image = tf.image.decode_image(tf.io.read_file(str(path)))\n",
    "            except Exception:\n",
    "                continue\n",
    "            yield image, tf.constant(label_str2int[path.parents[0].stem])\n",
    "\n",
    "    label_str2int = {'cat': 0, 'dog': 1}\n",
    "    ds_org = tf.data.Dataset.from_generator(generator,\n",
    "                                            (tf.float32, tf.int32),\n",
    "                                            (tf.TensorShape([None, None, 3]), tf.TensorShape([])))\n",
    "    ds_filtered = ds_org.filter(filter_small)\n",
    "\n",
    "    # filter smaller than 96x96\n",
    "    num_samples = ds_filtered.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
    "    num_samples_train = int(num_samples * 0.9)\n",
    "    ds_train = ds_filtered.take(num_samples_train)\n",
    "    ds_test = ds_filtered.skip(num_samples_train)\n",
    "\n",
    "    return (ds_train, num_samples_train), (ds_test, num_samples - num_samples_train), ['cat', 'dog'], 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習\n",
    "\n",
    "自分のメモリ容量に応じて、`buffer_size`, `batch_size` を調整。\n",
    "\n",
    "  - buffer_size: メインメモリに関係。\n",
    "  - batch_size: GPU側メモリに関係。\n",
    "\n",
    "ラベルは、One-hotベクトルを使うので、`CategoricalCrossentropy`にしている。\n",
    "\n",
    "epochsはコメントアウトしてある回数を指定する。  \n",
    "ルールで回数が指定されているので回しきる。EarlyStoppingは使わない。  \n",
    "※お試しで、10回にしてるだけ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(bit_model: WrappedBiT, dst_dir: pathlib.Path, dataset_factory, cache_dir, buffer_size=None, batch_size=512):\n",
    "    rule, ds_train, ds_test, label_names = setup_dataset_and_hyperrule(\n",
    "        dataset_factory, cache_dir, buffer_size=buffer_size, batch_size=batch_size)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    bit_model.compile(optimizer=rule.optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        # tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=str(dst_dir / 'tmp.ckpt'), verbose=1, save_best_only=True),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=str(dst_dir / 'tfboard'), histogram_freq=1, write_images=1),\n",
    "    ]\n",
    "\n",
    "    bit_model.fit(\n",
    "        ds_train,\n",
    "        batch_size=rule.batch_size,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=10, # rule.steps // 10,\n",
    "        validation_data=ds_test,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    bit_model.save(str(dst_dir / 'model'), save_format='tf')\n",
    "    (dst_dir / 'label_names.json').write_text(json.dumps(label_names, ensure_ascii=False), encoding='utf-8')\n",
    "\n",
    "\n",
    "def main(version='1'):\n",
    "    tf.get_logger().setLevel(logging.ERROR)\n",
    "    for d in tf.config.experimental.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(d, True)\n",
    "\n",
    "    bit_type = 'm-r50x1'\n",
    "    model = WrappedBiT(classes=2, bit_type=bit_type)\n",
    "\n",
    "    # ds_factory = dataset_mydataset\n",
    "    ds_factory = dataset_cats_vs_dogs\n",
    "\n",
    "    model_dir = pathlib.Path(f'models/{bit_type}/{version}')\n",
    "    cache_dir = pathlib.Path('cache/cats_dogs')\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "    cache_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    train(model, model_dir, ds_factory, cache_dir, buffer_size=2000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8562\n",
      "Epoch 00001: val_loss improved from inf to 0.04375, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.3496 - accuracy: 0.8562 - val_loss: 0.0438 - val_accuracy: 0.9939\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9781\n",
      "Epoch 00002: val_loss improved from 0.04375 to 0.02656, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2552 - accuracy: 0.9781 - val_loss: 0.0266 - val_accuracy: 0.9931\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9797\n",
      "Epoch 00003: val_loss improved from 0.02656 to 0.02466, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.0952 - accuracy: 0.9797 - val_loss: 0.0247 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9781\n",
      "Epoch 00004: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.1132 - accuracy: 0.9781 - val_loss: 0.0255 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9531\n",
      "Epoch 00005: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2259 - accuracy: 0.9531 - val_loss: 0.0326 - val_accuracy: 0.9939\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9828\n",
      "Epoch 00006: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.1888 - accuracy: 0.9828 - val_loss: 0.0352 - val_accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9891\n",
      "Epoch 00007: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.1770 - accuracy: 0.9891 - val_loss: 0.0472 - val_accuracy: 0.9961\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9609\n",
      "Epoch 00008: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 61s 6s/step - loss: 0.1537 - accuracy: 0.9609 - val_loss: 0.0639 - val_accuracy: 0.9944\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9672\n",
      "Epoch 00009: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2199 - accuracy: 0.9672 - val_loss: 0.0766 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.9625\n",
      "Epoch 00010: val_loss did not improve from 0.02466\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.2628 - accuracy: 0.9625 - val_loss: 0.0924 - val_accuracy: 0.9818\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
