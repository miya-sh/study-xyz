{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigTransfer (BiT) Fine-Tuning\n",
    "\n",
    "- 参考資料  \n",
    "  https://blog.tensorflow.org/2020/05/bigtransfer-bit-state-of-art-transfer-learning-computer-vision.html\n",
    "\n",
    "以下メモ\n",
    "\n",
    "## BiT-HyperRule\n",
    "\n",
    "BiTをファインチューニングするために用意されているヒューリスティックな方法。  \n",
    "Hyper-parameterをランダム探索した方が、最適にはなるが非常にコストがかかるので、「この設定でやると、1回のファインチューニングでイイ感じになるよ」というもの。\n",
    "\n",
    "- 使用最適化アルゴリズム: SGD\n",
    "  - Learning rate: 0.003\n",
    "  - Momentum: 0.9\n",
    "  - 備考  \n",
    "  学習ステップが、30%, 60%, 90% になるタイミングで、学習率を$\\frac{1}{10}$ずつ減衰させる。\n",
    "\n",
    "> we decay the learning rate by a factor of 10 at 30%, 60% and 90% of the training steps.\n",
    "\n",
    "とあるけど、参考元のColabだと $\\frac{1}{10}, \\frac{1}{10}, ...$ と減衰させてない・・・ \n",
    "\n",
    "- バッチ数: 512  \n",
    "  → 512とかメモリ的に無理って人向けに、バッチサイズを小さくした際の処理（Learning Rate, step数の調整）がある。\n",
    "\n",
    "- 学習用データへの前処理\n",
    "  - リサイズ、ランダムクリップ、水平方向へのランダムフリップを行う。リサイズする画像サイズは、参考資料のTable 1。\n",
    "  - タスクの種類によっては行わない方がいい処理アリ。（正解ラベルと乖離が出てしまう）\n",
    "    - 物体の数え上げ ⇒ ランダムクリップはNG。\n",
    "    - 物体の位置特定 ⇒ ランダムフリップはNG。\n",
    "  - MixUpの利用  \n",
    "    使用するデータセットで、使うか否かの判断基準あり。\n",
    "\n",
    "- 学習ステップ  \n",
    "  データセットのサイズで決定される。\n",
    "\n",
    "- その他\n",
    "  - データセットの画像サイズでリサイズ指定あるけど、96px以下がたまに含まれてるとかある場合どうするんだろうか？  \n",
    "    今回は、フィルターして除いてしまう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataclasses\n",
    "import logging\n",
    "import pathlib\n",
    "import datetime\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "class WrappedBiT(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, classes=2, bit_type='m-r50x1', version='1'):\n",
    "        super().__init__()\n",
    "        self._head = tf.keras.layers.Dense(classes, kernel_initializer='zeros')\n",
    "        self._bit = tfhub.KerasLayer(f'https://tfhub.dev/google/bit/{bit_type}/{version}')\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        features = self._bit(inputs)\n",
    "        return self._head(features)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class HyperRule:\n",
    "    steps: int\n",
    "    resize_edge: int\n",
    "    crop_size: int\n",
    "    optimizer: tf.keras.optimizers.Optimizer\n",
    "\n",
    "    def __init__(self, image_edge: int, dataset_size: int, batch_size=512):\n",
    "        assert 512 % batch_size == 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if image_edge < 96:\n",
    "            self.resize_edge, self.crop_size = 160, 128\n",
    "        else:\n",
    "            self.resize_edge, self.crop_size = 512, 480\n",
    "\n",
    "        if dataset_size < 20 * 10 ** 3:\n",
    "            steps, boundaries = 500, [200, 300, 400]\n",
    "        elif 20 * 10 ** 3 <= dataset_size < 500 * 10 ** 3:\n",
    "            steps, boundaries = 10000, [3000, 6000, 9000]\n",
    "        else:\n",
    "            steps, boundaries = 20000, [6000, 12000, 18000]\n",
    "        self.steps = steps * 512 // batch_size\n",
    "\n",
    "        lr = 0.003 * batch_size / 512\n",
    "        lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "            boundaries=boundaries, values=[lr, lr * 1e-1, lr * 1e-2, lr * 1e-3]\n",
    "        )\n",
    "        self.optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=lr_schedule, momentum=0.9\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データセットの準備\n",
    "\n",
    "`dataset_cats_and_dogs`\n",
    "\n",
    "今回は犬猫を選択。手元にラベル付きデータの準備がないとかなら、Tensorflow Datasetsから拝借できる。  \n",
    "ここでは、一辺96px以下になるような画像はフィルターし、残った全体の80%を学習、20%をバリデーションに使う。\n",
    "\n",
    "`setup_dataset_and_hyperrule`\n",
    "\n",
    "データセットにHyperRuleを適応しつつ、キャッシュとか順序シャッフルもセットアップ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_cats_and_dogs():\n",
    "    def filter_small(image, _):\n",
    "        return tf.reduce_all(tf.shape(image)[:2] > tf.constant(96))\n",
    "\n",
    "    ds_org: tf.data.Dataset\n",
    "    (ds_org, ), info = tfds.load(name='cats_vs_dogs', with_info=True, as_supervised=True, split=['train'])\n",
    "    ds_filtered = ds_org.filter(filter_small)\n",
    "\n",
    "    # filter smaller than 96x96\n",
    "    num_samples = ds_filtered.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
    "    num_samples_train = int(num_samples * 0.8)\n",
    "    ds_train = ds_filtered.take(num_samples_train)\n",
    "    ds_test = ds_filtered.skip(num_samples_train)\n",
    "\n",
    "    label_names = info.features['label'].names\n",
    "    return (ds_train, num_samples_train), (ds_test, num_samples - num_samples_train), label_names, 97\n",
    "\n",
    "\n",
    "def setup_dataset_and_hyperrule(ds_factory, cache_dir, buffer_size=None, batch_size=512):\n",
    "    def resize_normalize(image, label):\n",
    "        image = tf.image.resize(image, [rule.resize_edge, rule.resize_edge],\n",
    "                                method=tf.image.ResizeMethod.BILINEAR)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image, label\n",
    "\n",
    "    def random_sampling(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_crop(image, [rule.crop_size, rule.crop_size, 3])\n",
    "        return image, label\n",
    "\n",
    "    (ds_train, ds_train_size), (ds_test, _), label_names, image_edge = ds_factory()\n",
    "\n",
    "    rule = HyperRule(image_edge=image_edge, dataset_size=ds_train_size, batch_size=batch_size)\n",
    "    ds_train = (ds_train\n",
    "                .map(resize_normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                .cache(str(cache_dir / 'train'))\n",
    "                .shuffle(buffer_size or ds_train_size)\n",
    "                .repeat()\n",
    "                .map(random_sampling, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                .batch(rule.batch_size)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "    ds_test = (ds_test\n",
    "               .map(resize_normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "               .cache(str(cache_dir / 'test'))\n",
    "               .batch(rule.batch_size)\n",
    "               .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    return rule, ds_train, ds_test, label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset_mydataset`\n",
    "\n",
    "自分でデータ持ってる用。小さい画像(96px以下)をフィルターして、全体の90%を学習、10%をバリデーションに使う。シャッフルした後に分割する。  \n",
    "パス情報なら、メモリへの負担は比較的マシやろと乱暴に全体シャッフルしてる。あんまよくないと思う。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_mydataset():\n",
    "    def filter_small(image, _):\n",
    "        return tf.reduce_all(tf.shape(image)[:2] > tf.constant(96))\n",
    "\n",
    "    def generator():\n",
    "        path_iter = itertools.chain(pathlib.Path('train/cat').iterdir(), pathlib.Path('train/dog').iterdir())\n",
    "        path_list = list(path_iter)\n",
    "        for path in filter(lambda p: p.suffix in {'.png', '.jpg'}, random.sample(path_list, len(path_list))):\n",
    "            try:\n",
    "                image = tf.image.decode_image(tf.io.read_file(str(path)))\n",
    "            except Exception:\n",
    "                continue\n",
    "            yield image, tf.constant(label_str2int[path.parents[0].stem])\n",
    "\n",
    "    label_str2int = {'cat': 0, 'dog': 1}\n",
    "    ds_org = tf.data.Dataset.from_generator(generator,\n",
    "                                            (tf.float32, tf.int32),\n",
    "                                            (tf.TensorShape([None, None, 3]), tf.TensorShape([])))\n",
    "    ds_filtered = ds_org.filter(filter_small)\n",
    "\n",
    "    # filter smaller than 96x96\n",
    "    num_samples = ds_filtered.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
    "    num_samples_train = int(num_samples * 0.9)\n",
    "    ds_train = ds_filtered.take(num_samples_train)\n",
    "    ds_test = ds_filtered.skip(num_samples_train)\n",
    "\n",
    "    return (ds_train, num_samples_train), (ds_test, num_samples - num_samples_train), ['cat', 'dog'], 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習の準備\n",
    "\n",
    "自分のメモリ容量に応じて、`buffer_size`, `batch_size` 調整して学習始める。\n",
    "\n",
    "- epochsはコメントアウトしてある回数を指定する。\n",
    "  - 最初はテストで、10回くらいとかでいい。\n",
    "- ルールで回数が指定されているので回しきる。EarlyStoppingは使わない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(bit_model: WrappedBiT, dst_dir: pathlib.Path, dataset_factory, cache_dir, buffer_size=None, batch_size=512):\n",
    "    rule, ds_train, ds_test, label_names = setup_dataset_and_hyperrule(\n",
    "        dataset_factory, cache_dir, buffer_size=buffer_size, batch_size=batch_size\n",
    "    )\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    bit_model.compile(optimizer=rule.optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        # tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=str(dst_dir / 'tmp.ckpt'), verbose=1, save_best_only=True),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=str(dst_dir / 'tfboard'), histogram_freq=1, write_images=1),\n",
    "    ]\n",
    "\n",
    "    bit_model.fit(\n",
    "        ds_train,\n",
    "        batch_size=rule.batch_size,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=10, # rule.steps // 10,\n",
    "        validation_data=ds_test,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    bit_model.save(str(dst_dir / 'model'), save_format='tf')\n",
    "    (dst_dir / 'label_names.json').write_text(json.dumps(label_names, ensure_ascii=False), encoding='utf-8')\n",
    "\n",
    "\n",
    "def main():\n",
    "    tf.get_logger().setLevel(logging.ERROR)\n",
    "    for d in tf.config.experimental.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(d, True)\n",
    "\n",
    "    bit_type = 'm-r50x1'\n",
    "    model = WrappedBiT(classes=2, bit_type=bit_type)\n",
    "\n",
    "    version = '1'\n",
    "    ds_factory = dataset_mydataset\n",
    "\n",
    "    model_dir = pathlib.Path(f'models/{bit_type}/{version}')\n",
    "    cache_dir = pathlib.Path('cache/cats_dogs')\n",
    "    model_dir.mkdir(exist_ok=False, parents=True)\n",
    "    cache_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    train(model, model_dir, ds_factory, cache_dir, buffer_size=2000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8781\n",
      "Epoch 00001: val_loss improved from inf to 0.03761, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.2726 - accuracy: 0.8781 - val_loss: 0.0376 - val_accuracy: 0.9899\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9922\n",
      "Epoch 00002: val_loss improved from 0.03761 to 0.02982, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 0.0298 - val_accuracy: 0.9937\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9969\n",
      "Epoch 00003: val_loss improved from 0.02982 to 0.01091, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9922\n",
      "Epoch 00004: val_loss improved from 0.01091 to 0.00988, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0123 - accuracy: 0.9922 - val_loss: 0.0099 - val_accuracy: 0.9987\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9937\n",
      "Epoch 00005: val_loss improved from 0.00988 to 0.00966, saving model to models\\m-r50x1\\1\\tmp.ckpt\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0146 - accuracy: 0.9937 - val_loss: 0.0097 - val_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9953\n",
      "Epoch 00006: val_loss did not improve from 0.00966\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.0110 - val_accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9937\n",
      "Epoch 00007: val_loss did not improve from 0.00966\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0133 - accuracy: 0.9937 - val_loss: 0.0111 - val_accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9906\n",
      "Epoch 00008: val_loss did not improve from 0.00966\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0194 - accuracy: 0.9906 - val_loss: 0.0106 - val_accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9891\n",
      "Epoch 00009: val_loss did not improve from 0.00966\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0218 - accuracy: 0.9891 - val_loss: 0.0143 - val_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9953\n",
      "Epoch 00010: val_loss did not improve from 0.00966\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0109 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
